Gravando log em: logs/xceptionNet/V1/log_treino_df.txt
Número de imagens no dataset de treino: 76507
Número de imagens no dataset de validação: 9563

Classes detectadas no treino: ['fake', 'real']
Mapeamento de classe para índice: {'fake': 0, 'real': 1}
/home/sato/virtualpy/lib/python3.13/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name xception to current legacy_xception.
  model = create_fn(
GPU: NVIDIA GeForce RTX 2060
Parametros treináveis:
  block12.skip.weight
  block12.skipbn.weight
  block12.skipbn.bias
  block12.rep.1.conv1.weight
  block12.rep.1.pointwise.weight
  block12.rep.2.weight
  block12.rep.2.bias
  block12.rep.4.conv1.weight
  block12.rep.4.pointwise.weight
  block12.rep.5.weight
  block12.rep.5.bias
  conv3.conv1.weight
  conv3.pointwise.weight
  bn3.weight
  bn3.bias
  conv4.conv1.weight
  conv4.pointwise.weight
  bn4.weight
  bn4.bias
  fc.1.weight
  fc.1.bias

EPOCH 1/10
------------------------------
[Train] epoch 1/10 step 100/2391 loss_mean=0.4975
[Train] epoch 1/10 step 200/2391 loss_mean=0.4629
[Train] epoch 1/10 step 300/2391 loss_mean=0.4639
[Train] epoch 1/10 step 400/2391 loss_mean=0.4597
[Train] epoch 1/10 step 500/2391 loss_mean=0.4442
[Train] epoch 1/10 step 600/2391 loss_mean=0.4601
[Train] epoch 1/10 step 700/2391 loss_mean=0.4587
[Train] epoch 1/10 step 800/2391 loss_mean=0.4558
[Train] epoch 1/10 step 900/2391 loss_mean=0.4481
[Train] epoch 1/10 step 1000/2391 loss_mean=0.4589
[Train] epoch 1/10 step 1100/2391 loss_mean=0.4638
[Train] epoch 1/10 step 1200/2391 loss_mean=0.4259
[Train] epoch 1/10 step 1300/2391 loss_mean=0.4454
[Train] epoch 1/10 step 1400/2391 loss_mean=0.4460
[Train] epoch 1/10 step 1500/2391 loss_mean=0.4415
[Train] epoch 1/10 step 1600/2391 loss_mean=0.4348
[Train] epoch 1/10 step 1700/2391 loss_mean=0.4631
[Train] epoch 1/10 step 1800/2391 loss_mean=0.4366
[Train] epoch 1/10 step 1900/2391 loss_mean=0.4359
[Train] epoch 1/10 step 2000/2391 loss_mean=0.4300
[Train] epoch 1/10 step 2100/2391 loss_mean=0.4499
[Train] epoch 1/10 step 2200/2391 loss_mean=0.4446
[Train] epoch 1/10 step 2300/2391 loss_mean=0.4373
[Val]   epoch 1/10 step 100/299 loss_mean=0.2157
[Val]   epoch 1/10 step 200/299 loss_mean=0.2168
Train Loss: 0.4499 | Train Acc: 0.8288
Val Loss: 0.4433 | Val   Acc: 0.8298
 Best model saved to models/xceptionNet/V1/model_df.pt (Val Acc: 0.8298)

EPOCH 2/10
------------------------------
[Train] epoch 2/10 step 100/2391 loss_mean=0.4456
[Train] epoch 2/10 step 200/2391 loss_mean=0.4413
[Train] epoch 2/10 step 300/2391 loss_mean=0.4403
[Train] epoch 2/10 step 400/2391 loss_mean=0.4350
[Train] epoch 2/10 step 500/2391 loss_mean=0.4384
[Train] epoch 2/10 step 600/2391 loss_mean=0.4431
[Train] epoch 2/10 step 700/2391 loss_mean=0.4269
[Train] epoch 2/10 step 800/2391 loss_mean=0.4482
[Train] epoch 2/10 step 900/2391 loss_mean=0.4253
[Train] epoch 2/10 step 1000/2391 loss_mean=0.4075
[Train] epoch 2/10 step 1100/2391 loss_mean=0.4350
[Train] epoch 2/10 step 1200/2391 loss_mean=0.4290
[Train] epoch 2/10 step 1300/2391 loss_mean=0.4518
[Train] epoch 2/10 step 1400/2391 loss_mean=0.4544
[Train] epoch 2/10 step 1500/2391 loss_mean=0.4397
[Train] epoch 2/10 step 1600/2391 loss_mean=0.4352
[Train] epoch 2/10 step 1700/2391 loss_mean=0.4263
[Train] epoch 2/10 step 1800/2391 loss_mean=0.4292
[Train] epoch 2/10 step 1900/2391 loss_mean=0.4375
[Train] epoch 2/10 step 2000/2391 loss_mean=0.4363
[Train] epoch 2/10 step 2100/2391 loss_mean=0.4522
[Train] epoch 2/10 step 2200/2391 loss_mean=0.4356
[Train] epoch 2/10 step 2300/2391 loss_mean=0.4396
[Val]   epoch 2/10 step 100/299 loss_mean=0.2174
[Val]   epoch 2/10 step 200/299 loss_mean=0.2177
Train Loss: 0.4364 | Train Acc: 0.8293
Val Loss: 0.4379 | Val   Acc: 0.8301
 Best model saved to models/xceptionNet/V1/model_df.pt (Val Acc: 0.8301)

EPOCH 3/10
------------------------------
[Train] epoch 3/10 step 100/2391 loss_mean=0.4343
[Train] epoch 3/10 step 200/2391 loss_mean=0.4369
[Train] epoch 3/10 step 300/2391 loss_mean=0.4283
[Train] epoch 3/10 step 400/2391 loss_mean=0.4276
[Train] epoch 3/10 step 500/2391 loss_mean=0.4541
[Train] epoch 3/10 step 600/2391 loss_mean=0.4183
[Train] epoch 3/10 step 700/2391 loss_mean=0.4333
[Train] epoch 3/10 step 800/2391 loss_mean=0.4376
[Train] epoch 3/10 step 900/2391 loss_mean=0.4458
[Train] epoch 3/10 step 1000/2391 loss_mean=0.4224
[Train] epoch 3/10 step 1100/2391 loss_mean=0.4320
[Train] epoch 3/10 step 1200/2391 loss_mean=0.4453
[Train] epoch 3/10 step 1300/2391 loss_mean=0.4139
[Train] epoch 3/10 step 1400/2391 loss_mean=0.4300
[Train] epoch 3/10 step 1500/2391 loss_mean=0.4348
[Train] epoch 3/10 step 1600/2391 loss_mean=0.4377
[Train] epoch 3/10 step 1700/2391 loss_mean=0.4354
[Train] epoch 3/10 step 1800/2391 loss_mean=0.4189
[Train] epoch 3/10 step 1900/2391 loss_mean=0.4518
[Train] epoch 3/10 step 2000/2391 loss_mean=0.4421
[Train] epoch 3/10 step 2100/2391 loss_mean=0.4206
[Train] epoch 3/10 step 2200/2391 loss_mean=0.4173
[Train] epoch 3/10 step 2300/2391 loss_mean=0.4534
[Val]   epoch 3/10 step 100/299 loss_mean=0.2316
[Val]   epoch 3/10 step 200/299 loss_mean=0.2306
Train Loss: 0.4332 | Train Acc: 0.8297
Val Loss: 0.4378 | Val   Acc: 0.8302
 Best model saved to models/xceptionNet/V1/model_df.pt (Val Acc: 0.8302)

EPOCH 4/10
------------------------------
[Train] epoch 4/10 step 100/2391 loss_mean=0.4419
[Train] epoch 4/10 step 200/2391 loss_mean=0.4396
[Train] epoch 4/10 step 300/2391 loss_mean=0.4276
[Train] epoch 4/10 step 400/2391 loss_mean=0.4186
[Train] epoch 4/10 step 500/2391 loss_mean=0.4325
[Train] epoch 4/10 step 600/2391 loss_mean=0.4428
[Train] epoch 4/10 step 700/2391 loss_mean=0.4280
[Train] epoch 4/10 step 800/2391 loss_mean=0.4306
[Train] epoch 4/10 step 900/2391 loss_mean=0.4196
[Train] epoch 4/10 step 1000/2391 loss_mean=0.4271
[Train] epoch 4/10 step 1100/2391 loss_mean=0.4355
[Train] epoch 4/10 step 1200/2391 loss_mean=0.4373
[Train] epoch 4/10 step 1300/2391 loss_mean=0.4433
[Train] epoch 4/10 step 1400/2391 loss_mean=0.4475
[Train] epoch 4/10 step 1500/2391 loss_mean=0.4356
[Train] epoch 4/10 step 1600/2391 loss_mean=0.4280
[Train] epoch 4/10 step 1700/2391 loss_mean=0.4208
[Train] epoch 4/10 step 1800/2391 loss_mean=0.4396
[Train] epoch 4/10 step 1900/2391 loss_mean=0.4335
[Train] epoch 4/10 step 2000/2391 loss_mean=0.4228
[Train] epoch 4/10 step 2100/2391 loss_mean=0.4256
[Train] epoch 4/10 step 2200/2391 loss_mean=0.4425
[Train] epoch 4/10 step 2300/2391 loss_mean=0.4259
[Val]   epoch 4/10 step 100/299 loss_mean=0.2086
[Val]   epoch 4/10 step 200/299 loss_mean=0.2080
Train Loss: 0.4322 | Train Acc: 0.8296
Val Loss: 0.4334 | Val   Acc: 0.8299

EPOCH 5/10
------------------------------
[Train] epoch 5/10 step 100/2391 loss_mean=0.4178
[Train] epoch 5/10 step 200/2391 loss_mean=0.4247
[Train] epoch 5/10 step 300/2391 loss_mean=0.4435
[Train] epoch 5/10 step 400/2391 loss_mean=0.4395
[Train] epoch 5/10 step 500/2391 loss_mean=0.4190
[Train] epoch 5/10 step 600/2391 loss_mean=0.4292
[Train] epoch 5/10 step 700/2391 loss_mean=0.4318
[Train] epoch 5/10 step 800/2391 loss_mean=0.4175
[Train] epoch 5/10 step 900/2391 loss_mean=0.4355
[Train] epoch 5/10 step 1000/2391 loss_mean=0.4264
[Train] epoch 5/10 step 1100/2391 loss_mean=0.4205
[Train] epoch 5/10 step 1200/2391 loss_mean=0.4343
[Train] epoch 5/10 step 1300/2391 loss_mean=0.4447
[Train] epoch 5/10 step 1400/2391 loss_mean=0.4412
[Train] epoch 5/10 step 1500/2391 loss_mean=0.4450
[Train] epoch 5/10 step 1600/2391 loss_mean=0.4271
[Train] epoch 5/10 step 1700/2391 loss_mean=0.4451
[Train] epoch 5/10 step 1800/2391 loss_mean=0.4282
[Train] epoch 5/10 step 1900/2391 loss_mean=0.4297
[Train] epoch 5/10 step 2000/2391 loss_mean=0.4168
[Train] epoch 5/10 step 2100/2391 loss_mean=0.4336
[Train] epoch 5/10 step 2200/2391 loss_mean=0.4206
[Train] epoch 5/10 step 2300/2391 loss_mean=0.4374
[Val]   epoch 5/10 step 100/299 loss_mean=0.2304
[Val]   epoch 5/10 step 200/299 loss_mean=0.2286
Train Loss: 0.4309 | Train Acc: 0.8303
Val Loss: 0.4351 | Val   Acc: 0.8306
 Best model saved to models/xceptionNet/V1/model_df.pt (Val Acc: 0.8306)

EPOCH 6/10
------------------------------
[Train] epoch 6/10 step 100/2391 loss_mean=0.4296
[Train] epoch 6/10 step 200/2391 loss_mean=0.4211
[Train] epoch 6/10 step 300/2391 loss_mean=0.4242
[Train] epoch 6/10 step 400/2391 loss_mean=0.4529
[Train] epoch 6/10 step 500/2391 loss_mean=0.4464
[Train] epoch 6/10 step 600/2391 loss_mean=0.4292
[Train] epoch 6/10 step 700/2391 loss_mean=0.4297
[Train] epoch 6/10 step 800/2391 loss_mean=0.4259
[Train] epoch 6/10 step 900/2391 loss_mean=0.4259
[Train] epoch 6/10 step 1000/2391 loss_mean=0.4296
[Train] epoch 6/10 step 1100/2391 loss_mean=0.4442
[Train] epoch 6/10 step 1200/2391 loss_mean=0.4377
[Train] epoch 6/10 step 1300/2391 loss_mean=0.4374
[Train] epoch 6/10 step 1400/2391 loss_mean=0.4240
[Train] epoch 6/10 step 1500/2391 loss_mean=0.4367
[Train] epoch 6/10 step 1600/2391 loss_mean=0.4378
[Train] epoch 6/10 step 1700/2391 loss_mean=0.4301
[Train] epoch 6/10 step 1800/2391 loss_mean=0.4274
[Train] epoch 6/10 step 1900/2391 loss_mean=0.4177
[Train] epoch 6/10 step 2000/2391 loss_mean=0.4186
[Train] epoch 6/10 step 2100/2391 loss_mean=0.4389
[Train] epoch 6/10 step 2200/2391 loss_mean=0.4227
[Train] epoch 6/10 step 2300/2391 loss_mean=0.4292
[Val]   epoch 6/10 step 100/299 loss_mean=0.2226
[Val]   epoch 6/10 step 200/299 loss_mean=0.2208
Train Loss: 0.4303 | Train Acc: 0.8298
Val Loss: 0.4330 | Val   Acc: 0.8302

EPOCH 7/10
------------------------------
[Train] epoch 7/10 step 100/2391 loss_mean=0.4282
[Train] epoch 7/10 step 200/2391 loss_mean=0.4314
[Train] epoch 7/10 step 300/2391 loss_mean=0.4216
[Train] epoch 7/10 step 400/2391 loss_mean=0.4273
[Train] epoch 7/10 step 500/2391 loss_mean=0.4234
[Train] epoch 7/10 step 600/2391 loss_mean=0.4373
[Train] epoch 7/10 step 700/2391 loss_mean=0.4190
[Train] epoch 7/10 step 800/2391 loss_mean=0.4355
[Train] epoch 7/10 step 900/2391 loss_mean=0.4362
[Train] epoch 7/10 step 1000/2391 loss_mean=0.4418
[Train] epoch 7/10 step 1100/2391 loss_mean=0.4418
[Train] epoch 7/10 step 1200/2391 loss_mean=0.4382
[Train] epoch 7/10 step 1300/2391 loss_mean=0.4382
[Train] epoch 7/10 step 1400/2391 loss_mean=0.4067
[Train] epoch 7/10 step 1500/2391 loss_mean=0.4181
[Train] epoch 7/10 step 1600/2391 loss_mean=0.4412
[Train] epoch 7/10 step 1700/2391 loss_mean=0.4243
[Train] epoch 7/10 step 1800/2391 loss_mean=0.4379
[Train] epoch 7/10 step 1900/2391 loss_mean=0.4280
[Train] epoch 7/10 step 2000/2391 loss_mean=0.4299
[Train] epoch 7/10 step 2100/2391 loss_mean=0.4284
[Train] epoch 7/10 step 2200/2391 loss_mean=0.4094
[Train] epoch 7/10 step 2300/2391 loss_mean=0.4347
[Val]   epoch 7/10 step 100/299 loss_mean=0.2369
[Val]   epoch 7/10 step 200/299 loss_mean=0.2355
Train Loss: 0.4296 | Train Acc: 0.8301
Val Loss: 0.4354 | Val   Acc: 0.8305

EPOCH 8/10
------------------------------
[Train] epoch 8/10 step 100/2391 loss_mean=0.4367
[Train] epoch 8/10 step 200/2391 loss_mean=0.4457
[Train] epoch 8/10 step 300/2391 loss_mean=0.4398
[Train] epoch 8/10 step 400/2391 loss_mean=0.4090
[Train] epoch 8/10 step 500/2391 loss_mean=0.4200
[Train] epoch 8/10 step 600/2391 loss_mean=0.4269
[Train] epoch 8/10 step 700/2391 loss_mean=0.4194
[Train] epoch 8/10 step 800/2391 loss_mean=0.4344
[Train] epoch 8/10 step 900/2391 loss_mean=0.4391
[Train] epoch 8/10 step 1000/2391 loss_mean=0.4195
[Train] epoch 8/10 step 1100/2391 loss_mean=0.4338
[Train] epoch 8/10 step 1200/2391 loss_mean=0.4399
[Train] epoch 8/10 step 1300/2391 loss_mean=0.4373
[Train] epoch 8/10 step 1400/2391 loss_mean=0.4181
[Train] epoch 8/10 step 1500/2391 loss_mean=0.4225
[Train] epoch 8/10 step 1600/2391 loss_mean=0.4301
[Train] epoch 8/10 step 1700/2391 loss_mean=0.3984
[Train] epoch 8/10 step 1800/2391 loss_mean=0.4370
[Train] epoch 8/10 step 1900/2391 loss_mean=0.4536
[Train] epoch 8/10 step 2000/2391 loss_mean=0.4400
[Train] epoch 8/10 step 2100/2391 loss_mean=0.4324
[Train] epoch 8/10 step 2200/2391 loss_mean=0.4216
[Train] epoch 8/10 step 2300/2391 loss_mean=0.4249
[Val]   epoch 8/10 step 100/299 loss_mean=0.2059
[Val]   epoch 8/10 step 200/299 loss_mean=0.2048
Train Loss: 0.4293 | Train Acc: 0.8300
Val Loss: 0.4308 | Val   Acc: 0.8303

EPOCH 9/10
------------------------------
[Train] epoch 9/10 step 100/2391 loss_mean=0.4217
[Train] epoch 9/10 step 200/2391 loss_mean=0.4355
[Train] epoch 9/10 step 300/2391 loss_mean=0.4173
[Train] epoch 9/10 step 400/2391 loss_mean=0.4169
[Train] epoch 9/10 step 500/2391 loss_mean=0.4309
[Train] epoch 9/10 step 600/2391 loss_mean=0.4264
[Train] epoch 9/10 step 700/2391 loss_mean=0.4250
[Train] epoch 9/10 step 800/2391 loss_mean=0.4318
[Train] epoch 9/10 step 900/2391 loss_mean=0.4305
[Train] epoch 9/10 step 1000/2391 loss_mean=0.4203
[Train] epoch 9/10 step 1100/2391 loss_mean=0.4439
[Train] epoch 9/10 step 1200/2391 loss_mean=0.4409
[Train] epoch 9/10 step 1300/2391 loss_mean=0.4324
[Train] epoch 9/10 step 1400/2391 loss_mean=0.4296
[Train] epoch 9/10 step 1500/2391 loss_mean=0.4330
[Train] epoch 9/10 step 1600/2391 loss_mean=0.4073
[Train] epoch 9/10 step 1700/2391 loss_mean=0.4334
[Train] epoch 9/10 step 1800/2391 loss_mean=0.4502
[Train] epoch 9/10 step 1900/2391 loss_mean=0.4213
[Train] epoch 9/10 step 2000/2391 loss_mean=0.4297
[Train] epoch 9/10 step 2100/2391 loss_mean=0.4364
[Train] epoch 9/10 step 2200/2391 loss_mean=0.4319
[Train] epoch 9/10 step 2300/2391 loss_mean=0.4259
[Val]   epoch 9/10 step 100/299 loss_mean=0.2131
[Val]   epoch 9/10 step 200/299 loss_mean=0.2120
Train Loss: 0.4289 | Train Acc: 0.8302
Val Loss: 0.4313 | Val   Acc: 0.8307
 Best model saved to models/xceptionNet/V1/model_df.pt (Val Acc: 0.8307)

EPOCH 10/10
------------------------------
[Train] epoch 10/10 step 100/2391 loss_mean=0.4140
[Train] epoch 10/10 step 200/2391 loss_mean=0.4354
[Train] epoch 10/10 step 300/2391 loss_mean=0.4290
[Train] epoch 10/10 step 400/2391 loss_mean=0.4377
[Train] epoch 10/10 step 500/2391 loss_mean=0.4092
[Train] epoch 10/10 step 600/2391 loss_mean=0.4181
[Train] epoch 10/10 step 700/2391 loss_mean=0.4316
[Train] epoch 10/10 step 800/2391 loss_mean=0.4148
[Train] epoch 10/10 step 900/2391 loss_mean=0.4388
[Train] epoch 10/10 step 1000/2391 loss_mean=0.4248
[Train] epoch 10/10 step 1100/2391 loss_mean=0.4159
[Train] epoch 10/10 step 1200/2391 loss_mean=0.4284
[Train] epoch 10/10 step 1300/2391 loss_mean=0.4383
[Train] epoch 10/10 step 1400/2391 loss_mean=0.4235
[Train] epoch 10/10 step 1500/2391 loss_mean=0.4266
[Train] epoch 10/10 step 1600/2391 loss_mean=0.4563
[Train] epoch 10/10 step 1700/2391 loss_mean=0.4437
[Train] epoch 10/10 step 1800/2391 loss_mean=0.4329
[Train] epoch 10/10 step 1900/2391 loss_mean=0.4589
[Train] epoch 10/10 step 2000/2391 loss_mean=0.4350
[Train] epoch 10/10 step 2100/2391 loss_mean=0.4183
[Train] epoch 10/10 step 2200/2391 loss_mean=0.4150
[Train] epoch 10/10 step 2300/2391 loss_mean=0.4414
[Val]   epoch 10/10 step 100/299 loss_mean=0.2424
[Val]   epoch 10/10 step 200/299 loss_mean=0.2410
Train Loss: 0.4298 | Train Acc: 0.8297
Val Loss: 0.4364 | Val   Acc: 0.8306
Melhor acc: 0.8307

Tempo total de treino: 164m 3s
